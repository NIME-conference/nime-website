@InProceedings{nime2011-music-Troyer2011,
  author    = {Akito van Troyer, Jason Freeman, Avinash Sastry, Sang Won Lee, Shannon Yao},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {LOLC},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  In LOLC, the musicians in the laptop orchestra use a textual performance interface, developed specifically for this piece, to create and share rhythmic motives based on a collection of recorded sounds. The environment encourages musicians to share their code with each other, developing an improvisational conversation over time as material is looped, borrowed, and transformed. LOLC was originally created by Akito van Troyer and Jason Freeman and is in active development at the Georgia Tech Center for Music Technology by Jason Freeman, Andrew Colella, Sang Won Lee and Shannon Yao. LOLC is supported by a grant from the National Science Foundation as part of a larger research project on musical improvisation in performance and education (NSF CreativeIT#0855758).

About the performers:

Aaron Albin, Andrew Colella, Sertan Sentürk and Sang Won Lee are current degree candidates or alumni from the Georgia Tech Center for Music Technology. All are focused on exploring new methods of musical interactivity through projects that involve current technology such as the Kinect, swarm robots, creative video games, and current MIR techniques.},
  url       = {https://vimeo.com/26678685},
}

@InProceedings{nime2011-music-Brandtsegg2011,
  author    = {Øyvind Brandtsegg and Carl Haakon Waadeland},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Little Soldier Joe},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The duo Little Soldier Joe uses percussion and live processing to explore thematic and textural ideas that arise in the improvised interplay between these two performers. LSJ uses live sampling and manipulation matter-of-factly as an established manner of music making. The audio manipulation techniques used are based on recent developments in particle synthesis.

About the performers:

Øyvind Brandtsegg: Composer, musician and professor in music technology at NTNU. His focus lies in Compositionally Enabled Instruments, Particle Synthesis and sound installations. Øyvind has performed with the groups Krøyt and Motorpsycho, written music for interactive dance, theatre and TV, and worked as a programmer for other artists. His latest effort in music software programming is the “Hadron Particle Synthesizer”, to be released as a device for “Ableton Live”' and as a VST plug-in.

Carl Haakon Waadeland: Musician, composer and professor in music at NTNU. His main scientific interest lies within empirical rhythm research and the construction of models that simulate rhythm performance. Waadeland has performed and recorded amongst others with Gary Holton & Casino Steel, Warne Marsh, Siris Svale Band, Mikis Theodorakis & Arja Saijonmaa, Dadafon, and Rasmus og Verdens Beste Band. Waadeland published a book and CD on the Norwegian folk drum tradition in 2008.},
  url       = {https://vimeo.com/26680018},
}

@InProceedings{nime2011-music-Lopez2011,
  author    = {Carles López},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Reactable},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The Reactable was conceived in 2003 and was first presented at the International Computer Music Conference (ICMC) 2005 in Barcelona. Since then, the Reactable team has given more than 300 presentations and concerts in 40 countries, turning it into one of the most worldwide acclaimed new musical instruments of the 21st century. Since 2009, the Barcelona spin-off company Reactable Systems has been producing several Reactable models, such as the Reactable Live for traveling musicians and DJs, or its latest incarnation, Reactable mobile for Apple's iPhones and iPads.

About the performers:

Carles López: Musician, producer and DJ born in Barcelona. López has been playing with the Reactable for the last three years. With this instrument he has performed in more than 40 countries, at all kinds of events, clubs and festivals. López also works as a composer for films and contemporary dance.},
  url       = {https://vimeo.com/26678704},
}

@InProceedings{nime2011-music-Selle2011,
  author    = {Jacob Selle and Stefan Weinzierl},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Licht \& Hiebe},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Licht & Hiebe (2010) is the first concert piece for the new Instrument: The ``Hexenkessel'' (witch's cauldron) is a modified 22" timpani that uses LLP technology to turn the drumhead into an intuitive multitouch-interface for the control of live-electronics \& dmx-stage-lights. The multitouch technique goes into symbiosis with a traditional instrument, keeping its acoustic qualities, but opening it to the vast possibilities of interactive multimedia. Besides the control of live-electronics the instrument features an interface to dmx-controlled stage-lights to create a situation of intense intermedial fireworks entirely controlled by the performer. The parts needed for this non-destructive timpani-hack cost less than \$500.

About the performers:

Jacob Sello (1976, Hamburg/Germany) studied Audio Engineering, Systematic Musicology and Multimedia Composition in Hamburg. He is highly interested in the exciting possibilities that arise from the conjunction of traditional acoustic instruments and state-of-the-art technology. Pieces for clarinet controlled RC- helicopters or DJ-driven pneumatically prepared disklavier pieces are the outcome.

Stefan Weinzierl (1985, Günzburg/Germany) is constantly searching for fascinating challenges beyond genre-boundaries; as a drummer in contemporary solo performances, classical ensembles and orchestras as well as in Jazz- and Rock/Pop bands. He graduated in educational sciences in Regensburg and completed the Percussion Master program at the HfMT Hamburg in 2010.},
  url       = {https://vimeo.com/27687788},
}

@InProceedings{nime2011-music-Clayton2011,
  author    = {Joshua Clayton},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {ROYGBIV},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Refraction of Your Gaze by Indeterminate Variables (ROYGBIV) is an effort to interface sound and the visible spectrum with digital and analog media. A collage of field recording, synth pad, and mechanical noise, ROYGBIV unfolds as wavelengths of light are read with discrete color sensors. Data is communicated through microcontrollers to custom audio software and a slide projector reproduces images of the natural world. ROYGBIV is concerned with fundamental properties of sensing, perception, and the technologies that mediate such experience. Metaphysical dimensions of color and sound are implied as the projected image and rainbow form a dialectic between reflection and refraction.

About the performers:

Joshua Clayton: New York-based artist whose work occupies a hybrid space of media art and language. His recent projects explore semiotics, mysticism, architecture and the urban landscape, and research-based forms of practice. Joshua has just completed a master's degree in Interactive Telecommunications from New York University.},
  url       = {https://vimeo.com/27690118},
}

@InProceedings{nime2011-music-Stewart2011,
  author    = {Andrew Stewart},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {With Winds (for soprano t-stick)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: The t-sticks grew out of a collaborative project by Joseph Malloch and composer D. Andrew Stewart, at McGill University. The first prototype was completed in 2006. The t-sticks form a family of tubular digital musical instruments, ranging in length from 0.6 metres (soprano) to 1.2 metres (tenor). They have been designed and constructed to allow a large variety of unique interaction techniques. As a result, a significant emphasis is placed on the gestural vocabulary required to manipulate and manoeuvre the instrument. The musical experience for both the performer and audience is characterised by a unique engagement between performer body and instrument.

About the performers: D. Andrew Stewart (Hexagram-MATRALAB, Concordia University, Montreal, Canada): composer, pianist, clarinettist and digital musical instrumentalist. Stewart has been working in the field of music composition since 1994.  Since 2000, he has been pursuing a career in live electronics -- gesture-controlled -- performance, after developing his own sensor-suit.},
  url       = {https://vimeo.com/28226070},
}

@InProceedings{nime2011-music-Mays2011,
  author    = {Tom Mays},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {L'instant},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: "L'instant" (2011) : Solo performance for Karlax instrument and laptop. Composed and performed by Tom Mays. Originally an 8 channel tape piece, it was completely re-constructed as a live solo for the composer performing on a Karlax instrument – a gestural controller developed by Da Fact in France (see http://www.dafact.com/). Musically, "L'instant" is a musical interpretation of subatomic instantons, employing rotation and layering of parts who's rhythms and timbres are built out of the combining and crossing of series of numbers... The scenario is roughly “from the big bang to entropy”, and a “surround sound” 5.1 diffusion space is critical to the sense of immersion within the rotating sound objects and textures.

About the performer: Tom Mays: composer, computer musician and teacher, teaches at the National Superior Conservatory of Music in Paris, and is currently working on PhD at the University of Paris 8 with Horacio Vaggione. He is especially interested in gestural performance of real-time computer systems for both written and improvised music, as well as in interaction between music and video.},
  url       = {https://vimeo.com/28238543},
}

@InProceedings{nime2011-music-Dupuis2011,
  author    = {Alexander Dupuis},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {All Hail the Dawn},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  An interactive audiovisual feedback loop forms the basis of All Hail the Dawn. The instrument contains two simple light-sensitive oscillators.  A crude spectral analysis in Max/MSP is used to filter the oscillators as well as looped buffers recorded from the instrument.  A matrix of the spectral analysis, interactively altered in Jitter using audio data, is projected back onto the instrument and performer as a series of shifting patterns.  This setup allows both the graphics and sound to drive each other, creating an evolving audiovisual relationship sensitive to slight changes in position, sound or processing.

About the performers:

Alexander Dupuis: composer, performer, and multimedia artist. His work involves live electronics and guitar, real-time graphics and 3D animation, feedback systems and audiovisual installations. He graduated from Brown University in 2010, and is currently working towards his Masters Degree in the Digital Musics program at Dartmouth College.},
  url       = {https://vimeo.com/27691545},
}

@InProceedings{nime2011-music-Nagashima2011,
  author    = {Yoichi Nagashima},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Ural Power},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: Live computer music (multimedia) work, composed in 2010 and premiered in Russia. For this work, the composer developed a new interface system for musical expression. The new interface has 8 channels of infrared-ray distance sensors. This instrument is set up with two mic-stands on the stage. The performer also wears the specially developed instrument called MiniBioMuse-III which is 16 channels EMG sensor of the performance. The graphic part of this work is real-time OpenGL 3D graphics, which is live-controlled by the performance. This work is programmed in Max/MSP/jitter environment.

About the performer: Yoichi Nagashima: composer/researcher/PE, was born in 1958 in Japan. Since 1991 he has been the director of the Art & Science Laboratory in Hamamatsu, Japan. He is a professor of Shizouka University of Art and Culture, Faculty of Design, Department of Art and Science. He was the General Chair of NIME04.},
  url       = {https://vimeo.com/27731875},
}

@InProceedings{nime2011-music-EPtrio–ErikaDonald2011,
  author    = {EP trio – Erika Donald, Ben Duinker and Eliot Britton},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Television Sky},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: Television Sky is a three-movement work composed by Eliot Britton. The movements (Channels 1, 2, 3) deal with various musical and physical elements that figure prominently in the EP trio's research: Gesture, Texture, and Rhythm. Each movement adopts a different approach to organizing sounds; these provide unique arenas to explore communication, expression, and synchronization issues arising in an electroacoustic chamber music ensemble.

About the performer: EP trio is a multi-faceted research group and performing ensemble. It is comprised of cellist Erika Donald, percussionist Ben Duinker, and composer/ turntablist Eliot Britton. They are based at McGill University in Montreal, Canada where they enjoy support from the Centre for Interdisciplinary Research in Music Media and Technology (CIRMMT).},
  url       = {https://vimeo.com/28241338},
}

@InProceedings{nime2011-music-SarahTaylor2011,
  author    = {Sarah Taylor, Maurizio Goina and Pietro Polotti},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Body Jockey},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {About the performers:

Sarah Taylor: Dancer, Choreographer trained at the Australian Ballet School (Degree in Dance), in Classical, Cunningham and Graham, Scholarship student to Martha Graham school in New York. Currently working with Cesc Gelabert, for the 2011 Grec Festival, Barcelona.

Maurizio Goina: Viola player and an audio-visual composer. Currently he is affiliated with the School of Music and New Technologies of the Conservatory of Trieste where he is developing, together with Pietro Polotti and with the collaboration of Sarah Taylor, the EGGS system for gesture sonification.

Pietro Polotti: Studied piano, composition and electronic music. He has a degree in physics from the University of Trieste. In 2002, he obtained a Ph.D. in Communication Systems from the EPFL, Switzerland. Presently, he teaches Electronic Music at the Conservatory Tartini of Trieste, Italy. He has been part of the EGGS project since 2008.},
  url       = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
}

@InProceedings{nime2011-music-Nicolls2011,
  author    = {Sarah Nicolls and Nick Gillian},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Improvisation for piano + motion capture system},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  SN: I wanted to get at the closest relationship possible between my hands and the resulting sound. Having worked with sampling and complex processing and various sensors such as EMG, motion capture with live sound as the source seemed a way to really get inside an improvisation system that was really live and really intuitive. You can judge for yourselves!,

NG: Sarah's movements are sensed using a Kinect 3D motion capture device and the gestures are recognised in real-time using the SEC, a machine learning toolbox that has been specifically developed for musician-computer interaction.

About the performers:

Sarah Nicolls UK-based experimental pianist and inventor of `Inside-out piano'; collaborative researcher with e.g. Atau Tanaka, PA Tremblay; concerts e.g. world premieres of Larry Goves' Piano Concerto, Richard Barrett's Mesopotamia/London Sinfonietta/BBC Radio; article in LMJ20; Senior Lecturer at Brunel University; funding: Arts and Humanities Research Council (AHRC), Brunel Research Initiative and Enterprise Fund (BRIEF), Arts Council England.

Nick Gillian Post-doctoral researcher currently working on an E.U. project entitled SIEMPRE at the Sonic Arts Research Centre, Belfast. Nick recently completed his PhD in Gesture Recognition for Musician-Computer Interaction under the supervision of R. Benjamin Knapp and Sile O'Modhrain. His interests are in machine learning and pattern recognition and applying these techniques to enable real-time musician-computer interaction.},
  url       = {https://vimeo.com/26678719},
}

@InProceedings{nime2011-music-Hayes2011,
  author    = {Lauren Sarah Hayes and Christos Michalakos},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Socks and Ammo},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Performer notes:
  Socks and Ammo for piano, percussion and live electronics, is a new work investigating novel methods of communication between laptop and performer, as well as performer and performer, in an improvisational setting. Enhancing traditional aural and visual cues, a network is established between laptops, providing direction and suggestion to and between performers. Tactile feedback is provided to performers in the form of tiny vibrations on the skin, opening up a further, yet covert, channel of information to transmit signals and cues, allowing for a more informed and focused performance.

About the performers:

Lauren Sarah Hayes: Composer and performer from Glasgow. Her recent practice focuses on realizing compositions for piano and live electronics, which unify extended technique, bespoke software and instrument augmentation. Undertaken at the University of Edinburgh, her research investigates audio-haptic relationships as performance strategies for performers of digital music.

Christos Michalakos: Composer and improviser from northern Greece. Working predominantly with percussion and live electronics, his music explores relationships between acoustic and electronic sound worlds, through an examination of methods for developing and augmenting his drum kit, forming part of his PhD research at the University of Edinburgh.

===  Recorded at:

11th International Conference on New Interfaces for Musical Expression. 30 May - 1 June 2011, Oslo, Norway.

http://www.nime2011.org},
  url       = {https://vimeo.com/26629807},
}

@InProceedings{nime2011-music-PaulStapleton2011,
  author    = {Paul Stapleton, Caroline Pugh, Adnan Marquez-Borbon and Cavan Fyans},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {E=MCH},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {About the performers:

E=MCH is a recently formed quartet featuring Belfast-based improvisers Paul Stapleton (BoSS \& Postcard Weevil), Caroline Pugh (Voice \& Analogue Cassette Decks, Zero-input Mixer), Adnan Marquez-Borbon (Feedback Bass Clarinet, Recording Modules \& Delay Lines) and Cavan Fyans (DIY Electronics). Memories, distortions of time and place, echoes from analogue delay lengths, solid state samplers, and modified vinyl all help shape the fabric of the music in response to its larger ecology. ``Okay so making instruments and playing on them is not new, can't really see that there is any new thought about how why and what here, but the sound sculpture looks nice.'' --- Cosmopolitan

Paul Stapleton: Sound artist, improviser and writer originally from Southern California, currently lecturing at the Sonic Arts Research Centre in Belfast (SARC). Paul designs and performs with a variety of custom made metallic sound sculptures, electronics and found objects in locations ranging from impro clubs in Cork to abandoned beaches on Vancouver Island.

Caroline Pugh: Scottish vocalist and performance artist. She deviously borrows analogue technologies and oral histories to create performances that present imagined constructions of traditional and popular culture.  With a background in both folk music and improvisation, she collaborates with people from any discipline and performs in a wide variety of venues including folk clubs, arts venues and cinemas.

Adnan Marquez-Borbon: Saxophonist, improviser, computer musician, and composer, currently a PhD student at SARC. His research emphasis is on the roles of learning models and skill development in the design of digital musical instruments. As a musician, his music focuses on improvisation and the electronic manipulation of sounds in real-time.

Cavan Fyans: PhD research student, instrument builder, noise maker \& improviser. Currently located at SARC, Cavan's research examines the spectator's cognition of interaction and performance in communicative interactions with technology. Cavan also devotes time to developing new and innovative ways of breaking cheap electronic toys (Circuit Bending) and (re)constructing circuitry for sonic creation (Hardware Hacking).},
  url       = {https://vimeo.com/26620232},
}

@InProceedings{nime2011-music-Alden2011,
  author    = {Christopher Alden},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {REMI Sings},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  REMI Sings is an electroacoustic performance for the bio-inspired Rhizomatic Experimental Musical Interface (REMI) and accordion. REMI is an interactive networked musical organism that receives sonic input from its environment, processes it based on the ever changing structure of its interior network, and generates a unique musical output. This rhizomatic network is a software structure modelled after the functioning and growth patterns of biological rhizomes, specifically the mycorrhizal association that form vital nutrient pathways for the majority of the planet's land-plant ecosystems. The performance REMI Sings highlights this interface's interactive nature, creating a dialogue between human performer and non-human musical intelligence.

About the performer:

Christopher Alden: Composer, programmer, and instrumentalist currently studying at New York University's Interactive Telecommunications Program, where his research focuses on interactive music systems for composition and performance. Before ITP, he received his undergraduate degree in Music Theory and Composition at NYU where he studied composition under Marc Antonio-Consoli},
  url       = {https://vimeo.com/26619152},
}

@InProceedings{nime2011-music-Schwarz2011,
  author    = {Diemo Schwarz and Victoria Johnson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Suspended Beginnings},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The performance between electric violinist Victoria Johnson and Diemo Schwarz playing his interactive corpus-based concatenative synthesis software CataRT is an improvisation with two brains and four hands controlling one shared symbolic instrument, the sound space, built-up from nothing and nourished in unplanned ways by the sound of the instrument, explored and consumed with whatever the live instant filled it with. It creates a symbiotic relationship between the player of the instrument and that of the software. Live corpus-based concatenative synthesis permits here a new approach to improvisation, where sound from an instrument is recontextualised by interactive, gesture-controlled software. Not knowing what can happen is an integral part of the performance.

About the performers:

Victoria Johnson works with electric violin, live electronics, improvisation and musical technological issues in her artistic work. Trained as a classical violinist in Oslo, Vienna and London, she gave her debut recital in Oslo in 1995. She has established herself internationally as a soloist, chamber musician and improviser in contemporary, improvised and experimental, cross-disciplinary music and art.

Diemo Schwarz: Researcher and developer at Ircam, composer of electronic music, and musician on drums and laptop with gestural controllers. His compositions and live performances, in solo as Mean Time Between Failure, or improvising with other musicians, explore the possibilities of corpus-based concatenative synthesis to re-contextualise any sound source by rearranging sound units into a new musical framework using interactive navigation through a timbral space.},
  url       = {https://vimeo.com/26679877},
}

@InProceedings{nime2011-music-JasonDixon2011,
  author    = {Jason Dixon, Tom Davis, Jason Geistweidt and Alain B. Renaud},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {The Loop},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  The Loop explores the possibilities of co-located performance, decentralized composition, and the acoustics of network. This performance begins with a brief improvisation presenting acoustic sources to excite the network. This material is shared, transformed, and reintroduced into the composition. This process continues through successive generations until a predetermined time or a point at which the composition naturally concludes. The result is an integrated meta-instrument and an emergent composition, with no one artist being the sole performer or composer. Remote participants are represented locally by a mono speaker enabling the audiences to hear the transformation of audio through the networked instrument.

About the performers:

Jason Dixon: Irish composer currently based in Norwich where he is in the process of completing his PhD in composition. His work explores issues of language, perception and memory in music. More recently he has been focusing on the Irish storytelling tradition and its place in contemporary Ireland.

Tom Davis: Digital artist working mainly in the medium of sound installation. His practice and theory based output involves the creation of technology led environments for interaction. Davis is currently a lecturer at the University of Bournemouth and holds a PhD from the Sonic Arts Research Centre, Belfast.

Jason Geistweidt: Sound artist based at the University or Tromsø, Norway, researching mixed-reality stages and performance systems. He is a former faculty member of Interactive Arts and Media department at Columbia College Chicago. He holds PhD in electro-acoustic composition from the Sonic Arts Research Centre, Queens University, Belfast.

Alain B. Renaud: Alain's research focuses on networked music performance systems with an emphasis on the creation of strategies to interact over a network musically and the notion of shared networked acoustic spaces. He is a lecturer in at Bournemouth University, England and holds a PhD from the Sonic Arts Research Centre.},
  url       = {https://vimeo.com/26679893},
}

@InProceedings{nime2011-music-Zappi2011,
  author    = {Victor Zappi and Dario Mazzanti},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Dissonance},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  Dissonance is an audio/visual performance in which a progressive soundtrack is created along with the exploration of an interactive virtual environment. While real instrument--generated music animates the projected worlds, the two performers are allowed to physically interact with virtual objects, changing their position, shape and color to control music and create new sounds. As the journey continues and the environment introduces new elements and new metaphors, performers are driven to explore the sonic laws that rule each scenario. Spectators wearing 3D glasses perceive the virtual environment as moving out of the screen and embracing the artists, in choreographies where real and virtual world literally overlap.

About the performers:

Victor Zappi: PhD student and a new media artist. His research focuses on Virtual Reality and its applications in art and live performances.

Dario Mazzanti: computer science engineer and multi-instrumentalist composer. He enjoys writing, recording and playing music combining his artistic streak with his interest for technology.},
  url       = {https://vimeo.com/26616186},
}

@InProceedings{nime2011-music-Nowitz2011,
  author    = {Alex Nowitz},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {The Shells},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Since 2008 I have been performing and composing music for voice and live-electronics using two Wii-remotes as gestural controllers. The live-electronics function in two ways: as an extension of my voice and as an instrument as well. The music creation is mainly based on live-sampling the voice. I also use pre-recorded sounds and my own compositions. In addition, since the beginning of 2010 we have been developing a new instrument, which goes beyond the technical possibilities of the Wii-controllers. I call this instrument the Shells. Besides motion sensors there are three more continuous controllers available: a pressure sensor, a joystick control and ultrasound for distance measurement.

About the performers:

Alex Nowitz: Composer of vocal, chamber and electronic music as well as music for dance, theatre and opera. Furthermore, he is a voice artist, whistling and singing virtuoso who is classically trained as tenor and countertenor and presents a wide array of diverse and extended techniques. He has been artist in residence at STEIM, Amsterdam, since 2010.},
  url       = {https://vimeo.com/26661484},
}

@InProceedings{nime2011-music-Guillamat2011,
  author    = {Julien Guillamat, Charles Céleste Hutchins, Shelly Knotts, Norah Lorway, Jorge Garcia Moncada, Chris Tarren},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {BiLE (Birmingham Laptop Ensemble)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  An open playground for laptop improvisation and performance. BiLE's performance will focus on semi-structured improvisation, with players creating and manipulating sound using a variety of motion capture devices - iPhones, Wiimotes, and Xbox Kinect. The data captured by each device, along with analysed musical parameters, will be sent out over the shared network, to be used by each performer as they see fit. The aim is to allow players to latch onto other members of the group by mapping the shared data to their own software parameters, creating moments of convergence between the ensemble. BiLE takes an `instrumental' approach to performance, with each performer having their own speaker, sonic identity and spatial location.

About the performers:

BiLE (Birmingham Laptop Ensemble): A collaborative group of six composers, brought together through their shared interest in live performance and improvisation. BiLE has an open and inclusive attitude towards experimentation with sound, and draws on the members' wide-ranging musical backgrounds.},
  url       = {https://vimeo.com/26619928},
}

@InProceedings{nime2011-music-Quay2011,
  author    = {Yago de Quay and Ståle Skogstad},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Where Art Thou?: Dance Jockey},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  As artists, we have learned that throughout the history of mankind music and technology have co-evolved, shaping --- and being shaped by --- human expression and creativity. The variety and intricacy of these recombination processes contribute profoundly to the current diversity of performative structures and aesthetics within the arts. Where art Thou? is a 15 minute theatrical performance where sounds are controlled by sensors on the dancer's body. Blending a mixture of electronic music and sound effects with dance and acting, this novel act refocuses sensors from simplistic action-to-sound to contextualized aesthetic and dramatic expression. The name reflects the itinerant quality of the stage character as he travels through a world of sounds.

About the performers:

Yago de Quay: Interactive media artist, musician and researcher based in Porto. His numerous installations and performances focus on user participation contributing to modify the art piece itself. They always have a strong sonic component and combine technologies to help create new modes of expression. Yago is currently finishing his M.Sc. in Sound Design and Interactive Music at the Faculty of Engineering, University of Porto.

Ståle Skogstad: PhD student in the fourMs group at the University of Oslo. His research is focused on using real-time full-body motion capture technology for musical interaction. This includes real-time feature extraction from full body motion capture data and technical studies of motion capture technologies. He is currently working with the Xsens MVN inertial sensor suit.},
  url       = {https://vimeo.com/26619980},
}

@InProceedings{nime2011-music-Sciajno2011,
  author    = {Domenico Sciajno},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Sonolume},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  In this AV performance, images and sound interact: the basic elements of the images (brightness, color, saturation, hue, dislocation and relocation) are sensitive to the fundamental parameters of the sound being generated at that moment. Sound waves (also controlled by light waves during the performance) cross the physical world and alter the data stream that gives life to digital video in the same way that molecules are transformed by the sound contracting and expanding air particles in space.

About the performers:

Domenico Sciajno: Double bass player and composer of acoustic and electronic music. Thanks to his interest in improvisation and the influence of academic education, his research currently focuses on the creative possibilities provided by the interaction between acoustic instruments, indeterminacy factors and live processing by electronic devices or computers.},
  url       = {https://vimeo.com/26679879},
}

@InProceedings{nime2011-music-Aase2011,
  author    = {Tone Åse, Siri Gjære, Live Maria Roggen, Heidi Skjerve, Ingrid Lode, Kirsti Huke, Anita Kaasbøll, Silje R. Karlsen},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Trondheim Voices},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Trondheim Voices is in this performance exploring a new tool in their work with voice sound and improvisation. The ensemble is working with a tracking system for sound positioning to enable a given singer's position on stage to directly influence the sound processing, both spatialisation and effects. Through their improvisations and compositions they are exploring: a) The effect of the sound “following”' the singers' movements on stage. b) The flexible use of processed voice sound within the big vocal ensemble, through the control each singer gets over the sound output by moving on stage. c) The visualization of choices and changes regarding sound, both for the performer and the audience, through the movements of each singer on stage.

About the performers:

Trondheim Voices Professional ensemble, working with the endless possibilities within the field of vocal improvisation, to find new expressions and new music. Consisting of individual soloists, Trondheim Voices wishes to develop what happens when the unique soloist quality of each singer is set to interact with each other, and to find the collective sound and feeling. All of the singers are educated at NTNU, Trondheim, Norway.

Sound: Asle Karstad. Tracking system: John Torger Skjelstad},
  url       = {https://vimeo.com/26680007},
}

@InProceedings{nime2011-music-Hsu2011,
  author    = {Bill Hsu and Alain Crevoisier},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Interstices AP},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  Interstices AP is a structured audio-visual solo improvisation, using the multitouch Airplane Controller to manipulate live electronic sound and interactive animations. During the piece, Bill Hsu will be using the Airplane Controller in combination with his PSHIVA particle system software, to synthesize and interact with generative sound and animations. The visual component of Interstices AP is a physics-based simulation of a particle system. Particles, images and other components interact with physical gestures in a fluid like system; the results resemble asymmetric, constantly evolving Rorschach blots that open up a wide range of visual associations. For more details, see Bill Hsu's poster in the conference proceedings.

About the performers:

Bill Hsu: Associate Professor of Computer Science at San Francisco State University. His work with real-time audiovisual performance systems has been presented at (among others) SMC 2009 (Porto), Harvestworks Festival 2009 (New York), Fete Quaqua 2008 (London), MIX Festival 2007 and 2009 (New York), and Stimme+ 2006 (Karlsruhe).

Alain Crevoisier: Senior researcher at the Music Conservatory of Geneva, Switzerland. He is the founder of Future-instruments.net, a collaborative research network active in the field of new musical interfaces and interactive technologies. The latest realization is the Airplane controller, a portable system that makes possible to transform any flat surface, into a multitouch interface.},
  url       = {https://vimeo.com/26629820},
}

@InProceedings{nime2011-music-Hsu2011a,
  author    = {Bill Hsu, Håvard Skaset, Guro Skumsnes Moe},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Flayed/Flock},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Performer notes:

  Flayed/Flock is a structured audio-visual improvisation for three musicians, utilizing live acoustic and electronic sound and interactive animations. The visual component of Flayed/Flock is an enhanced flocking simulation that interacts with real-time audio from the performance of improvising musicians. Abstract patterns develop out of the flocking behavior; the flocks are also able to coalesce into well-defined symbols and forms such as crescents and stars, all while moving in a natural-looking manner consistent with flocking behavior. For more details, see Bill Hsu's poster in the conference proceedings.

About the performers:

Bill Hsu: Associate Professor of Computer Science at San Francisco State University. His work with real-time audiovisual performance systems has been presented at (among others) SMC 2009 (Porto), Harvestworks Festival 2009 (New York), Fete Quaqua 2008 (London), MIX Festival 2007 and 2009 (New York), and Stimme+ 2006 (Karlsruhe).

Håvard Skaset (guitar) and Guro Skumsnes Moe (bass): The Oslo-based duo works intensively in the borders between improv, noise and rock. Skaset and Moe play in bands including Bluefaced People, Art Directors, Sult, Mirror Trio, SEKSTETT, Telling Stories About Trees and MOE. They have been working with Christian Wolff, Pauline Oliveros, Fred Frith, Ikue Mori, Okkyung Lee, Frode Gjerstad and many more.},
  url       = {https://vimeo.com/26629835},
}

@InProceedings{nime2011-music-IvicaIcoBukvicDirector2011,
  author    = {Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {L2Ork},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:
  13 (Ivica Ico Bukvic): is a game of prime numbers and primal instincts pitting timbre against rhythm. Driven by conductor's oversight over an array of performer-specific and ensemble-wide parameters, a networked ensemble acts as one large meta-tracker where each individual performer contributes its own gesture-driven motives or tracks. The ensuing meta-tracker texture is superimposed against improvised acoustic percussion in a search of a meaningful discourse and ultimately musical synergy.

  Serene (Ivica Ico Bukvic): ...the one moment in the day when the world melts away and we catch a glimpse of life that just is... a celebration of this moment through juxtaposition of Taiji (Tai Chi Chuan) choreography and music...

 Citadel for soprano and L2Ork (Ivica Ico Bukvic) draws inspiration from a famous poem "Himna Slobodi" (Hymn to Freedom) by the 17th century Croatian poet Ivan Gundulic. As the first piece ever written for the newfound ensemble, it relies upon pervasive tonality, in many ways posing as an electronic counterpart to a traditional string ensemble. Using the infinite-bow metaphor to create lush tonal harmonies the piece forms a compelling aural foundation for a lyrical showcase of soloist's vocal talent.

=== About the performers:

L2Ork: Founded by Dr. Ivica Ico Bukvic in May 2009, is part of the latest interdisciplinary initiative by the Virginia Tech Music Department's Digital Interactive Sound \& Intermedia Studio (DISIS). As an emerging contemporary intermedia ensemble with a uniquely open design, L2Ork thrives upon the quintessential form of collaboration found in the western classical orchestra and its cross-pollination with increasingly accessible human-computer interaction technologies for the purpose of exploring expressive power of gesture, communal interaction, discipline-agnostic environment, and the multidimensionality of arts.

Members: Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek

===  Recorded at:

11th International Conference on New Interfaces for Musical Expression. 30 May - 1 June 2011, Oslo, Norway.

http://www.nime2011.org
About the performers:

L2Ork Founded by Dr. Ivica Ico Bukvic in May 2009, is part of the latest interdisciplinary initiative by the Virginia Tech Music Department's Digital Interactive Sound & Intermedia Studio (DISIS). As an emerging contemporary intermedia ensemble with a uniquely open design, L2Ork thrives upon the quintessential form of collaboration found in the western classical orchestra and its cross-pollination with increasingly accessible human-computer interaction technologies for the purpose of exploring expressive power of gesture, communal interaction, discipline-agnostic environment, and the multidimensionality of arts.

Members: Ivica Ico Bukvic (Director), John Elder, Hillary Guilliams, Bennett Layman, David Mudre, Steven Querry, Philip Seward, Andrew Street, Elizabeth Ullrich and Adam Wirdzek},
  url       = {https://vimeo.com/26678669},
  url2      = {https://vimeo.com/26678662},
  url3      = {https://vimeo.com/26643771},
}

@InProceedings{nime2011-music-Bokowiec2011,
  author    = {Mark Bokowiec and Julie Wilson-Bokowiec},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {V'Oct(Ritual)},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: V'Oct(Ritual) places the audience inside a circular liminal space of sonic evocation  and features the Bodycoder System© the first generation of which was developed by the artists in 1995.  The Bodycoder interface is a flexible sensor array worn on the body of a performer that sends data generated by movement to an MSP environment via radio. All vocalisations, decision making, navigation of the MSP environment and qualities of expressivity are selected, initiated and manipulated by the performer, uniquely, this also includes access to gestural control of live 8-channel spatialization.  This piece is fully scored with few moments of improvisation.

About the performers: Julie Wilson-Bokowiec: has created new works in opera/music theatre, contemporary dance and theatre and has worked with Lindsey Kemp, Genesis P-Orridge, Psychic TV and Hermann Nitsch.  Julie is a Research Fellow at CeReNem (Centre for Research in New Music) at the University of Huddersfield.
Mark Bokowiec: is the manager of the electroacoustic music studios and the Spacialization and Interactive Research Lab at the University of Huddersfield where he also lectures in interactive performance, interface design and composition.  Mark began creating work with interactive technologies in 1995.},
  url       = {https://vimeo.com/27694214},
}

@InProceedings{nime2011-music-Shiraishi2011,
  author    = {Satoshi Shiraishi and Alo Allik},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {mikro:strukt},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  mikro:strukt is a collaborative performance in which the custom-built e-clambone provides an acoustic source for the ensuing audiovisual environment. E-clambone is custom-built electronic instrument that consists of an aerophone supplied with haptic sensors and digital signal processing algorithms. The performance seeks to integrate elements of electro-acoustic improvisation, timbre composition and artificial intelligence based approach to autonomous audiovisual composition and explore micro level timbre composition in real time.

About the performers:

Satoshi Shiraishi: Electro-acoustic instrument designer/performer from Japan, currently living in The Hague, The Netherlands. He originally started his music carrier as a rock guitarist. After the meeting with computer music, he moved to The Netherlands to pursue his own way of playing computer generated sound on a stage.

Alo Allik: (Estonia) has a musically and geographically restless lifestyle, which has taken him through diverse musical worlds including DJ-ing and producing electronic dance music, live laptop jams, electroacoustic composition, free improvisation, audiovisual installations and performances.},
  url       = {https://vimeo.com/27694202},
}

@InProceedings{nime2011-music-Overholt2011,
  author    = {Dan Overholt and Lars Grausgaard},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Study No. 1 for Overtone Fiddle},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  This generative / improvisatory work uses an iPod Touch and a tactile sound transducer attached to the Overtone Fiddle's resonant body as a mobile system to lay out a variety of animated and transformed sound sources over time.

About the performers:

Dan Overholt: Associate Professor in the Department of Architecture, Design and Media Technology at Aalborg University, Denmark. He received a PhD in Media Arts and Technology from the University of California, Santa Barbara, a M.S. from the MIT Media Lab, and studied Music and Electronics Engineering and at CSU, Chico. As a musician, he composes and performs internationally with experimental human-computer interfaces and musical signal processing algorithms.

Lars Graugaard: Free-lance composer, laptop performer and researcher. He holds a PhD in Artistic and Technological Challenges of Interactive Music from Oxford Brookes University and a MS in flute performance from the Royal Danish Academy of Music. His main interest is the systematic study of music's expressive capacity applied to score composing, realtime interactive performance, generative and emergent music.},
  url       = {https://vimeo.com/26661494},
}

@InProceedings{nime2011-music-DougVanNort2011,
  author    = {Doug Van Nort, Pauline Oliveros and Jonas Braasch},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {Distributed Composition #1},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes:

  This piece is written in consideration of two distinct paradigms: telematic music performance and human-machine improvisation. Specifically this work is a structured improvisation for three humans and one intelligent agent, being constrained by sections that determine which pairing (duos, trios) of performers are active. Instrumentation also changes between sections in a way that blurs the line of agency and intent between acoustic human performers, laptop tablet-based human performer, and agent improviser, as the two remote (NY, Stanford) acoustic performers (v-accordion, soprano saxophone) engage with the on-stage laptop performer (GREIS system) and ambient presence of the agent performer (spatialization, loops, textures).

About the performers:

Doug Van Nort: Experimental musician and digital music researcher whose work includes composition, improvisation, interactive system design and cross-disciplinary collaboration. His writings can be found in Organised Sound and Leonardo Music Journal among other publications, and his music is documented on Deep Listening, Pogus and other labels.

Pauline Oliveros: (1932) is a composer and improviser, teaches at RPI, plays a Roland V Accordion in solo and ensemble improvisations. Her works are available through download, cassette, CD, DVD, and Vinyl releases. Oliveros founded the Deep Listening Institute, Ltd. based in Kingston NY.

Jonas Braasch: Experimental soprano saxophonist and acoustician with interests in Telematic Music and Intelligent Music Systems. He has performed with Curtis Bahn, Chris Chafe, Michael Century, Mark Dresser, Pauline Oliveros, Doug van Nort and Stuart Dempster -- among others. He currently directs the Communication Acoustics and Aural Architecture Research Laboratory at RPI.},
  url       = {https://vimeo.com/27691551},
}

@InProceedings{nime2011-music-Schorno2011,
  author    = {Daniel Schorno and Haraldur Karlsson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {7-of-12 dialectologies},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: The formalistic identity of ``7-of-12'' consists of a showcase format for ``penta digit instrumental inventions'' diffused in quadrophonic audio and 3d interactive video projection. The dialectic intertwining of Karlsson's abstract art and Schorno's sonetic world extends into a composition of 12'' duration. Eponymous instrument group ``EIG''' consist of two former classmates of Sonology where they among other things studied the making of alternative electronic instruments. The performance``7-of-12 dialectologies'' is an outcome of collaborated teachings and methodology in dialogue with past performances.

About the performers: Daniel Schorno: composer, born in Zurich in 1963. Studied composition in London with Melanie Daiken and electronic and computer music in The Hague, with Joel Ryan and Clarence Barlow. Invited by Michel Waisvisz he led STEIM - the re-nown Dutch Studio for Electro Instrumental Music, and home of ``New Instruments'' - as Artistic Director until 2005. He is currently STEIM's composer-in-research and creative project advisor.
Haraldur Karlsson: visual artist, born in Reykjavik 1967. Haraldur studied Multi-media in the art academy in Iceland, Media-art in AKI in Enschede and Sonology in the Royal conservatories The Hague. Haraldur is mainly focused on interactive audio/video/3D installations and performances, and instrumental computer controllers. His fire instrument ``TFI''' is part of the Little Solarsystem ``LSS'' navigation system that is an audio/video/3D performance.},
  url       = {https://vimeo.com/27694220},
}

@InProceedings{nime2011-music-Dahl2011,
  author    = {Luke Dahl and Carr Wilkerson},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  title     = {TweetDreams},
  year      = {2011},
  address   = {Oslo, Norway},
  editor    = {Kjell Tore Innervik and Ivar Frounberg},
  month     = jun,
  publisher = {Norwegian Academy of Music},
  abstract  = {Program notes: TweetDreams uses real-time Twitter data to generate music and visuals. During the performance tweets containing specific search terms are retrieved from Twitter. Each tweet is displayed and plays a short melody. Tweets are grouped into trees of related tweets, which are given similar melodies. We invite the audience to participate in TweetDreams by tweeting during performance with the term \emph{\#Nime2011}. This term is used to identify tweets from the audience and performers. Global search terms are used to bring the world into the performance. Any tweet with these terms occurring anywhere in the world becomes part of the piece.

About the performers: Luke Dahl: Musician and engineer currently pursuing a PhD at Stanford University's CCRMA. His research interests include new musical instruments and performance ensembles, musical gesture, rhythm perception, and MIR. He has composed works for the Stanford Laptop and Mobile Phone Orchestras and also creates electronic dance music.
Carr Wilkerson: System Administrator at CCRMA specializing in Linux and Mac OS systems. He is a controller and software system builder and sometime performer/impresario, instructor and researcher.},
  url       = {https://vimeo.com/27694232},
}

@Comment{jabref-meta: databaseType:bibtex;}
@inproceedings{nime19-music-Rust,
  author = {Anna R{\"u}st},
  title = {Bad Mother / Good Mother - an audiovisual performance},
  pages = {8--10},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Bad Mother / Good Mother is an audiovisual performance involving a projection, a modified electronic breast pump as a sound generator, and a sound- reactive LED pumping costume. The project has four songs that critically explore technologies directed specifically at women like breast pumps and fertility extending treatments such as egg-freezing (social freezing). Depending on the song, the breast pump is either a solo instrument or part of an arrangement. The idea is to use workplace lactation as a departure point to uncover a web of societal politics and pre-conceived perceptions (pun intended) of ideal and non-ideal motherhood.}
}

@inproceedings{nime19-music-DAlessandro,
  author = {Christophe D’Alessandro and Xiao Xiao and Grégoire Locqueville and Boris Doval},
  title = {Borrowed Voices},
  pages = {11--14},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music001.pdf},
  abstract = {Borrowed voices is a performance featuring performative voice synthesis, with two types of instruments: C-Voks and T-Voks. The voices are played a cappella in a double choir of natural and synthetic voices. Performative singing synthesis is a new paradigm in the already long history of artificial voices. The singing voice is played like an instrument, allowing singing with the borrowed voice of another. The relationship of embodiment between the singer’s gestures and the vocal sound produced is broken. A voice is singing, with realism, expressivity and musicality, but it is not the musician’s own voice, and a vocal apparatus does not control it. The project focuses on control gestures: the music explores vocal sounds produced by the vocal apparatus (the basic sound material), and “played” by the natural voice, by free-hand Theremin-controlled gestures, and by writing gestures on a graphic tablet. The same (types of) sounds but different gestures give different musical “instruments” and expressive possibilities. Another interesting aspect is the distance between synthetic voices and the player, the voice being at the same time embodied (by the player gestures playing the instrument with her/his body) and externalized (because the instrument is not her/his own voice): two different voices sung/played by the same person.}
}

@inproceedings{nime19-music-Dooley,
  author = {James Dooley},
  title = {colligation},
  pages = {15-16},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music003.pdf},
  abstract = {colligation (to bring or tie together) is a physical performance work for one performer that explores the idea of sculpting sound through gesture. Treating sound as if it were a tangible object capable of being fashioned into new sonic forms, "pieces" of sound are captured, shaped and sculpted by the performer's hand and arm gestures, appearing pliable as they are thrown around and transformed into new sonic material. colligation uses two Thalmic Labs Myo armbands, one placed on the left arm and the other on the right arm. The Myo Mapper [1] software is used to transmit scaled data via OSC from the armbands to Pure Data. Positional (yaw, pitch and roll) and electromyographic data (EMG) from the devices are mapped to parameters controlling a hybrid synth created in Pure Data. The synth utilises a combination of Phase Aligned Formant synthesis [2] and Frequency Modulation synthesis [3] to allow a range of complex audio spectra to be explored. Pitch, yaw and roll data from the left Myo are respectively mapped to the PAF synth’s carrier frequency (ranging from 8.175-12543.9Hz), bandwidth and relative centre frequency. Pitch, yaw and roll data from the right Myo are respectively mapped to FM modulation frequency (relative to and ranging from 0.01-10 times the PAF carrier frequency), modulation depth (relative to and ranging from 0.01-10 times the PAF carrier frequency), and modulation wave shape (crossfading between sine, triangle, square, rising sawtooth and impulse). Data from the left and right Myo's EMG sensors are mapped respectively to amplitude control of the left and right audio channels, giving the performer control over the level and panning of the audio within the stereo field. By employing both positional and bio data, an embodied relationship between action and response is created; the gesture and the resulting sonic transformation become inextricably entwined.}
}

@inproceedings{nime19-music-Ahn,
  author = {Sabina Hyoju Ahn},
  title = {DIY Bionoise},
  pages = {17--20},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music004.pdf},
  abstract = {DIY Bionoise (2018) is an instrument in which the performer can generate sound and noise, deriving from their own body. It contains a circuit that can measure the bioelectricity from living beings to control the instrument by tactile sense. This instrument has two functions – a modular synthesizer with an eight-step sequencer and a bionoise control mode.}
}

@inproceedings{nime19-music-Tom,
  author = {Ajin Tom},
  title = {FlexSynth – Blending Multi-Dimensional Sonic Scenes},
  pages = {21--24},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music005.pdf},
  abstract = {FlexSynth is an interpretation of The Sponge, a DMI embedded with sensors to detect squeeze, flexion and torsion along with buttons to form an interface using which musical sounds are generated and the sound is sculpted. The key idea of the sponge is to harness the properties of a retractable, flexible object that gives the performer wide range of multi- parametric controls with high resolution in a maximized gesture space, considering its high manoeuvrability.}
}

@inproceedings{nime19-music-Tragtenberg,
  author = {João Tragtenberg, Filipe Calegario},
  title = {Gira},
  pages = {25--28},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music006.pdf},
  abstract = {Gira is a music and dance performance with Giromin, a wearable wireless digital instrument. With this Digital Dance and Music Instrument a gesture is transformed into sound by motion sensors and an analog synthesizer. This transmutation of languages allows dance to generate music, which stimulates a new dance in an infinite feedback loop.}
}

@inproceedings{nime19-music-Cadiz,
  author = {Rodrigo F. Cádiz},
  title = {iCons},
  pages = {29--31},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music007.pdf},
  abstract = {iCons is an interactive multi-channel music piece for live computer and a gesture sensor system designed by the composer especially for this piece, called AirTouch. Such system allows a much more musical approach to controlling sounds than the computer keyboard or mouse. Using only movements of the hands in the air it is possible to control most aspects of the music, such as sound shapes in time, loops, space positioning, or create very rich spectral densities.}
}

@inproceedings{nime19-music-Galvao,
  author = {Martim Galvão},
  title = {MusiCursor},
  pages = {32--34},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music008.pdf},
  abstract = {MusiCursor is an interactive multimedia performance/interface that reimagines consumer-facing technologies as sites for creative expression. The piece draws inspiration from established UI/UX design paradigms and the role of the user in relation to these technologies. The performer assumes the role of a user installing a musically-driven navigation interface on their computer. After an installation prompt, they are guided through a series of demos, in which a software assistant instructs the performer to accomplish several tasks. Through their playing, the performer controls the cursor’s navigation and clicking behavior. In lieu of a traditional score, the performer relies on text instructions and visual indicators from a software assistant. The software tracks the progress of the user throughout the piece and moves onto the next section only once a task has been completed. Each of the main tasks takes place on the web, where the user navigates across YouTube, Wikipedia, and Google Maps.}
}

@inproceedings{nime19-music-Cullen,
  author = {Barry Cullen and Miguel Ortiz and Paul Stapleton},
  title = {Pandemonium Trio perform Drone and Drama v2},
  pages = {35--38},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music009.pdf},
  abstract = {Pandemonium Trio is Barry Cullen, Miguel Ortiz and Paul Stapleton. Our performance research trio has been set up to explore multiple instantiations of custom-made electronic instruments through improvisation. We are particularly interested in exploiting irregularities in the qualities of circuit components (e.g. imprecise tolerances/values), and how this allows for the development of stylistic differences across multiple instrument-performer configurations. We are also interested in how skill, style and performance techniques are developed in different ways on similar devices over extended periods of time, and how our existing musical practices are reconfigured through such collaborative exchanges.}
}

@inproceedings{nime19-music-DallAra-Majek,
  author = {Ana Dall’Ara-Majek and Takuto Fukuda},
  title = {Pythagorean Domino},
  pages = {39--42},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music010.pdf},
  abstract = {Pythagorean Domino is an improvisatory composition composed in 2019 for an augmented Theremin and a gyro-based gestural controller. This work aims to integrate music concrete techniques and an algorithmic compositional approach in the context of composition for gestural controllers. While music concrete compositional practice brings out the concept of “composite object”—a sound object made up of several distinct and successive elements [1]—in the piece, our algorithmic compositional approach delivers an interpolation technique which entails gradual transformations of the composite objects over time. Our challenge is to perform a chain of short fragmental elements in tandem in the way to form a single musical unit, while the algorithms for transformation are autonomously changing synthetic and control parameter settings. This approach derives closely interconnected triangular interactions between two performers and a computer.}
}

@inproceedings{nime19-music-Nie,
  author = {Yiyao Nie},
  title = {River},
  pages = {43--46},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music011.pdf},
  abstract = {“No one can step into the same river twice.” This instrument, named as River, contains rules and randomness. What exactly is music and how does it connect to and shape our form? Traditional musical instruments always have fixed physical forms that require performers to adjust to them. How about making a musical instrument that is more fluid and more expressive via deforming according to performers’ movements? This was the question I attempted to explore when I started making this project. For this project, I combine the movement of dancing with music to present a fluid and dynamic shape of musical instrument. The fabric of this instrument can be separated as an extension to wash. It’s portable, wireless, chargeable, stable and beautiful. This musical instrument generates sound by detecting different movements of the performer. It has four different modes selected by toggling the switches on the instrument interface. Each mode has different movement detection methods, generating various sound and music. Moreover, it can be played as a transmitting Tambourine. As for the music in my performance, it’s all played by myself lively, consisting of different sound triggered and changed by performers’ gestures and melody composed myself. Like the name of this instrument River, the four toggles and their detection methods and their corresponding generated sounds are intentionally designed. From simple node, beat, loop, drum, to various node, melody, music, the detection methods and their triggered sounds are becoming more and more complex and various, developing like a journey of a river.}
}

@inproceedings{nime19-music-Park,
  author = {Jiyun Park},
  title = {Self-Built Instrument (sound performance)},
  pages = {47--49},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music012.pdf},
  abstract = {Self-Built Instrument project is focused on sound performance with an experi- mental instrument which is composed of strings and metallic sound box, pro- ducing overtones, harmonics and feed- back. It is capable to play with different sound colours : Resonances by cooper, bowing on strings, overtones and feed- back. All of factors triggers each other’s sound. It is not a point to play a specific tone or to make a musical harmony, because the instrument is not able to per- fectly control. Playing this Instrument is a challenge to your capacity, such as gestures and sonic phenomenon following sense and space. The artist composed a piece and use few repertoire partly, however, mostly it is interesting to find what kind of sound comes to nest in mesh. The Artist tried to get over typical aesthetics of classical music, such as using precise pitches, melodies, and read scores. Instead of that, her approach towards to discover unusual sound elements which are considered as mistake in tradi- tional way. And play with them, for instance, strings without tuning, hitting a stuffs, unorganized pitch, also so-called clicker which happens unskilled.}
}

@inproceedings{nime19-music-Martins,
  author = {André L. Martins and Paulo Assis Barbosa},
  title = {Tanto Mar},
  pages = {50--51},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music013.pdf},
  abstract = {"Tanto Mar" seeks to recreate the properties present in history between Portugal and Brazil, embracing the idea of an aqueous sound that dances and moves as much by cadence as by voluminous waves. The Atlantic Ocean, which separates and unites the two countries, serves as an inspiration for this quadraphonic performance, involving musical instruments and live electronics, where the sounds move through the four speakers. Each speaker symbolizes the paths that the sea travels uninterruptedly, in a unique dance of latitudes and longitudes. The intersection of sounds occurs through processes of reverberations, spatializations, echoes, modulations and grains that slowly form the sound material, composing, decomposing and manipulating the sound waves. Sound characters such as wind, oars, storms, calm, among others, are metaphorically evidenced through the sound material, creating a kind of rhythmic movement of a caravel at sea. The sounds of "Tanto Mar" move between entropy and chaos, between stillness and tsunami, between starboard and port, culminating in a textural dance where the objective is to take the listener away from electronic processing, and propose a dive in an intensified, attentive, deep and involving listening. New musical possibilities can happen through the experimentation of new routes, unusual routes and horizons not yet covered. The sea and its imprecise distances represent permanent challenges. "Tanto Mar" seeks to revive the feeling of the Portuguese poet Fernando Pessoa, when he wrote: "to dream even if it is impossible".}
}

@inproceedings{nime19-music-Carrascoza,
  author = {Cassia Carrascoza and Felipe Merker Castellani},
  title = {Tempo Transversal – Flauta Expandida},
  pages = {52--55},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music014.pdf},
  abstract = {“Tempo Transversal – Flauta Expandida” aims to establish a computer- controlled catalyzer, which simultaneously combines and extends the flutist body actions, electronic sounds and the performative physical space. Some flute performance fragments, captured in real time by video cameras, besides pre-recorded images, built the visual projection. The flute player develops two pieces of experimental music for flute and electronic. All these heterogeneous elements are interrelated with each other in a network mediated by the computer. The result is a continuously unfolded interactive performance, which intends to manipulate settings of space-time perception. Brazilian contemporary repertoire for amplified bass flute and electronic sounds establishes the proposal.}
}

@inproceedings{nime19-music-Hamilton,
  author = {Rob Hamilton},
  title = {Trois Machins de la Grâce Aimante (Coretet no. 1)},
  pages = {56--59},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music015.pdf},
  abstract = {Trois Machins de la Grâce Aimante is a composition intended to explore Twenty-First century technological and musical paradigms. At its heart Trois Machins is a string quartet fundamentally descended from a tradition that spans back to the 18th century. As such, the work primarily explores timbral material based around the sound of a bowed string, in this case realized using a set of physically modeled bowed strings controlled by Coretet, a virtual reality string instrument and networked performance environment. The composition - for four performers, preferably from an existing string quartet ensemble - takes the form of three distinct movements, each exploring different capabilities of the instrument itself and requiring different forms of communication and collaboration between the four performers.}
}

@inproceedings{nime19-music-Stapleton,
  author = {Paul Stapleton},
  title = {uncertain rhythms},
  pages = {60--62},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music016.pdf},
  abstract = {This work is a continuation of my research into developing new performance ecosystems for improvisation. For this project I developed a new volatile assemblage, aka VOLA. My self-designed musical instruments are shaped by my history as a performer working in acoustic, mechanical, electronic and digital musics, blending and exploring the boundaries and breaking points of these different domains. My instruments support many of my existing techniques originally developed on more conventional instruments, while also affording the development of extended and novel techniques and performance strategies. In much of my work I am particularly focused on the exploration of musical timbre and texture; however, for this project my attention is also directed towards time, flow, pulse, duration, friction, disruption – in short, qualitative rhythms and defamiliarisation.}
}

@inproceedings{nime19-music-Erdem,
  author = {Çağri Erdem and Katja Henriksen Schia and Alexander Refsum Jensenius},
  title = {Vrengt: A Shared Body-Machine Instrument for Music-Dance Performance},
  pages = {63--65},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music017.pdf},
  abstract = {What if a musician could step outside the familiar instrumental paradigm and adopt a new embodied language for moving through sound with a dancer in true partnership? And what if a dancer’s body could coalesce with a musician’s skills and intuitively render movements into instrumental actions for active sound- making? Vrengt is a multi-user instrument, specifically developed for music-dance performance, with a particular focus on exploring the boundaries between standstill vs motion, and silence vs sound. We sought for creating a work for one, hybrid corporeality, in which a dancer and a musician would co-creatively and co- dependently interact with their bodies and a machine. The challenge, then, was how could two performers with distinct embodied skills unite in a continuous entanglement of intentions, senses and experiences to control the same sonic and musical parameters? This was conceptually different than they had done before in the context of interactive dance performances.}
}

@inproceedings{nime19-music-Barbosa,
  author = {Paulo Assis Barbosa and Miguel Antar},
  title = {We Bass: inter(actions) on a hybrid instrument},
  pages = {66--67},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music018.pdf},
  abstract = {The key for a collective process of free improvisation is the interaction, dependence and surrender of its parts, so the resulting sound flux is more than the sum of each individual layer. The We Bass performance is an exploration of the symbiosis of two performers playing the same instrument: Their actions have direct consequence on the resulting sound, challenging the other player with instability and interference. From the experiments of the English scientist Thomas Young (1773-1829) on the phenomena of diffraction and interference of light waves, we observe that interferences generated by overlapping light waves can have a character of annihilation, when they are out of phase (destructive interference), or a reinforcing character when in phase (constructive interference). From this reflection we try to deepen the discussion about the interferences of the performers inputs involved in a free improvisation session. We seek a model of connection between the performers that promotes processes of creation in the free improvisation, exploring the dialectics between reinforcement actions (processes of interaction that reinforces a certain sound moment) and movement actions (that destabilizes and transforms the flow). We Bass is a duo performance exploring the interactions between the musicians playing one hybrid machine: an electric upright bass guitar with live electronics processing. The instrument consists of an electric upright bass with movement sensors and a live processing machine with a controller that interacts with the sensors, changing some processing parameters and some controller mapping settings, creating an instable ground for the musicians.}
}

@inproceedings{nime19-music-introduction,
  author = {Federico Visi and Rodrigo Schramm},
  title = {Introduction},
  pages = {4},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music00I.pdf},
}

@inproceedings{nime19-music-program,
  title = {NIME 2019 Concert Program},
  pages = {5},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_music0II.pdf},
}

@inproceedings{nime19-music-PC-members,
  title = {NIME 2019 Program Committee Members},
  pages = {6},
  booktitle = {Music Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Federico Visi},
  year = {2019},
  month = {June},
  publisher = {UFRGS},
  address = {Porto Alegre, Brazil},
  URL = {http://www.nime.org/proceedings/2019/nime2019_musicIII.pdf},
}





