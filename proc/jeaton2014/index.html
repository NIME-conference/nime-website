<!-- copied out of alembic's default template. -->
<!doctype html>
<html lang="en-GB">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="manifest" href="/nime/manifest.json">
    <meta name="theme-color" content="#242e2b"/>
		<link rel="stylesheet" href="/nime/assets/styles.css">
    
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@16px.png" sizes="16x16">
    <link rel="apple-touch-icon" sizes="16x16" href="/assets/logos/logo@16px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@32px.png" sizes="32x32">
    <link rel="apple-touch-icon" sizes="32x32" href="/assets/logos/logo@32px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@96px.png" sizes="96x96">
    <link rel="apple-touch-icon" sizes="96x96" href="/assets/logos/logo@96px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@120px.png" sizes="120x120">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/logos/logo@120px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@144px.png" sizes="144x144">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/logos/logo@144px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@180px.png" sizes="180x180">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/logos/logo@180px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@512px.png" sizes="512x512">
    <link rel="apple-touch-icon" sizes="512x512" href="/assets/logos/logo@512px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@1024px.png" sizes="1024x1024">
    <link rel="apple-touch-icon" sizes="1024x1024" href="/assets/logos/logo@1024px.png">
  

<link rel="shortcut icon" href="/assets/logos/nime.png">

		<!-- Overwrite this file with code you want before the closing head tag -->


		
  </head>

	<body>
		<header class="header">
  <div class="container">
    <a class="logo" href="/nime/">
  <img src="/nime/assets/logos/nime.png" alt="NIME logo">
</a>


    
<nav class="nav  nav--header">
  <ul class="list  list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/">Home</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/past-nimes/">Past NIMEs</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/archives/">Proceedings</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/music/">Music</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/hosting/">Hosting</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/committee/">Committee</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/list/">Mailing List</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/statements/">Statements</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="https://forum.nime.org/">Forum</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/mentorship/">Mentorship</a>
      </li>
    
  </ul>
  <button class="button  button--nav" aria-label="Menu toggle">
    <svg width="16" height="16" class="icon  icon--nav" role="img" alt="Menu"><title>Menu</title>
<use xlink:href="#nav" fill="CurrentColor"></use></svg>

  </button>
</nav>


<script type="text/javascript">
  // Get list and button
  const navList = document.querySelector('.header .list--nav')
  const button  = document.querySelector('.header .button--nav')

  // Hide nav and apply toggle
  const collapseNav = () => {
    if (document.body.clientWidth < 640) {
      navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
    } else {
      navList.removeAttribute('style')
    }

    button.onclick = () => {
      navList.style.setProperty('transition', `margin .1s`)
      if (navList.style.getPropertyValue('--listHeight')) {
        navList.style.removeProperty('--listHeight')
      } else {
        navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
      }
    }
  }

  collapseNav()

  // Check on resize if to collapse nav
  window.addEventListener('resize', () => {
    collapseNav()
  })
</script>

  </div>

  






</header>

		<main class="main container">
			<article class="article article--page content typeset">
				
				<h1>The Space Between Us. A Live Performance with Musical Score Generated via Emotional Levels Measured in EEG of One Performer and an Audience Member</h1>
				
				<h4>



Joel Eaton, Weiwei Jin, and Eduardo Miranda</h4>
				
				<p>Proceedings of the International Conference on New Interfaces for Musical Expression</p>
				
				<ul>
					<li>Year: 2014</li>
					<li>Location: London, United Kingdom</li>
					
					<li>Pages: 593–596</li>
					
					
					<li>DOI: <a href="https://doi.org/10.5281/zenodo.1178756">10.5281/zenodo.1178756 (Link to paper)</a>
</li>
					
					
					
					
					
				</ul>
				
				<h2>Abstract:</h2>
				
				<p>The Space Between Us is a live performance piece for vocals, piano and live electronics using a Brain-Computer Music Interface system for emotional control of the score. The system not only aims to reflect emotional states but to direct and induce emotional states through the real-time generation of the score, highlighting the potential of direct neural-emotional manipulation in live performance. The EEG of the vocalist and one audience member is measured throughout the performance and the system generates a real-time score based on mapping the emotional features within the EEG. We measure the two emotional descriptors, valence and arousal, within EEG and map the two-dimensional correlate of averaged windows to musical phrases. These pre-composed phrases contain associated emotional content based on the KTH Performance Rules System (Director Musices). The piece is in three movements, the first two are led by the emotions of each subject respectively, whilst the third movement interpolates the combined response of the performer and audience member. The system not only aims to reflect the individuals' emotional states but also attempts to induce a shared emotional experience by drawing the two responses together. This work highlights the potential available in affecting neural-emotional manipulation within live performance and demonstrates a new approach to real-time, affectively-driven composition.</p>

				<h2>Citation:</h2>

				



Joel Eaton, Weiwei Jin, and Eduardo Miranda. 2014. 


The Space Between Us. A Live Performance with Musical Score Generated via Emotional Levels Measured in EEG of One Performer and an Audience Member. 


<em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 
DOI: <a href="https://doi.org/10.5281/zenodo.1178756">10.5281/zenodo.1178756</a>



				<h2>BibTeX Entry:</h2>

<pre>
@inproceedings{jeaton2014,
 abstract = {The Space Between Us is a live performance piece for vocals, piano and live electronics using a Brain-Computer Music Interface system for emotional control of the score. The system not only aims to reflect emotional states but to direct and induce emotional states through the real-time generation of the score, highlighting the potential of direct neural-emotional manipulation in live performance. The EEG of the vocalist and one audience member is measured throughout the performance and the system generates a real-time score based on mapping the emotional features within the EEG. We measure the two emotional descriptors, valence and arousal, within EEG and map the two-dimensional correlate of averaged windows to musical phrases. These pre-composed phrases contain associated emotional content based on the KTH Performance Rules System (Director Musices). The piece is in three movements, the first two are led by the emotions of each subject respectively, whilst the third movement interpolates the combined response of the performer and audience member. The system not only aims to reflect the individuals' emotional states but also attempts to induce a shared emotional experience by drawing the two responses together. This work highlights the potential available in affecting neural-emotional manipulation within live performance and demonstrates a new approach to real-time, affectively-driven composition.},
 address = {London, United Kingdom},
 author = {Joel Eaton and Weiwei Jin and Eduardo Miranda},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.1178756},
 issn = {2220-4806},
 month = {June},
 pages = {593--596},
 publisher = {Goldsmiths, University of London},
 title = {The Space Between Us. A Live Performance with Musical Score Generated via Emotional Levels Measured in {EEG} of One Performer and an Audience Member},
 url = {http://www.nime.org/proceedings/2014/nime2014_418.pdf},
 year = {2014}
}

</pre>
			</article>
		</main>
		<footer class="footer">
  <div class="container">
    <div class="copyright  typeset">
      <small class="small">© NIME 2024</small>
    </div>

    
<nav class="nav  nav--footer">
  <ul class="list list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/#top">Back to top</a>
      </li>
    
  </ul>
</nav>


  </div>
</footer>

	</body>
</html>
