<!-- copied out of alembic's default template. -->
<!doctype html>
<html lang="en-GB">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="manifest" href="/nime/manifest.json">
    <meta name="theme-color" content="#242e2b"/>
		<link rel="stylesheet" href="/nime/assets/styles.css">
    
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@16px.png" sizes="16x16">
    <link rel="apple-touch-icon" sizes="16x16" href="/assets/logos/logo@16px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@32px.png" sizes="32x32">
    <link rel="apple-touch-icon" sizes="32x32" href="/assets/logos/logo@32px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@96px.png" sizes="96x96">
    <link rel="apple-touch-icon" sizes="96x96" href="/assets/logos/logo@96px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@120px.png" sizes="120x120">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/logos/logo@120px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@144px.png" sizes="144x144">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/logos/logo@144px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@180px.png" sizes="180x180">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/logos/logo@180px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@512px.png" sizes="512x512">
    <link rel="apple-touch-icon" sizes="512x512" href="/assets/logos/logo@512px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@1024px.png" sizes="1024x1024">
    <link rel="apple-touch-icon" sizes="1024x1024" href="/assets/logos/logo@1024px.png">
  

<link rel="shortcut icon" href="/assets/logos/nime.png">

		<!-- Overwrite this file with code you want before the closing head tag -->


		
  </head>

	<body>
		<header class="header">
  <div class="container">
    <a class="logo" href="/nime/">
  <img src="/nime/assets/logos/nime.png" alt="NIME logo">
</a>


    
<nav class="nav  nav--header">
  <ul class="list  list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/">Home</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/past-nimes/">Past NIMEs</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/archives/">Proceedings</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/music/">Music</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/hosting/">Hosting</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/committee/">Committee</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/list/">Mailing List</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/statements/">Statements</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="https://forum.nime.org/">Forum</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/mentorship/">Mentorship</a>
      </li>
    
  </ul>
  <button class="button  button--nav" aria-label="Menu toggle">
    <svg width="16" height="16" class="icon  icon--nav" role="img" alt="Menu"><title>Menu</title>
<use xlink:href="#nav" fill="CurrentColor"></use></svg>

  </button>
</nav>


<script type="text/javascript">
  // Get list and button
  const navList = document.querySelector('.header .list--nav')
  const button  = document.querySelector('.header .button--nav')

  // Hide nav and apply toggle
  const collapseNav = () => {
    if (document.body.clientWidth < 640) {
      navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
    } else {
      navList.removeAttribute('style')
    }

    button.onclick = () => {
      navList.style.setProperty('transition', `margin .1s`)
      if (navList.style.getPropertyValue('--listHeight')) {
        navList.style.removeProperty('--listHeight')
      } else {
        navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
      }
    }
  }

  collapseNav()

  // Check on resize if to collapse nav
  window.addEventListener('resize', () => {
    collapseNav()
  })
</script>

  </div>

  






</header>

		<main class="main container">
			<article class="article article--page content typeset">
				
				<h1>BachDuet: A Deep Learning System for Human-Machine Counterpoint Improvisation</h1>
				
				<h4>



Christodoulos Benetatos, Joseph VanderStel, and Zhiyao Duan</h4>
				
				<p>Proceedings of the International Conference on New Interfaces for Musical Expression</p>
				
				<ul>
					<li>Year: 2020</li>
					<li>Location: Birmingham, UK</li>
					
					<li>Pages: 635–640</li>
					
					
					<li>DOI: <a href="https://doi.org/10.5281/zenodo.4813234">10.5281/zenodo.4813234</a>
</li>
					<li><a href="https://www.nime.org/proceedings/2020/nime2020_paper125.pdf">PDF link</a></li>
					<li><a href="https://youtu.be/wFGW0QzuPPk">Presentation Video</a></li>
					
					
					
				</ul>
				
				<h2>Abstract:</h2>
				
				<p>During theBaroque period, improvisation was a key element of music performance and education. Great musicians, such as J.S. Bach, were better known as improvisers than composers. Today,  however,  there  is  a  lack  of  improvisation culture in classical music performance and education; classical musicians either are not trained to improvise, or cannot find other people to improvise with.  Motivated by this observation,  we  develop BachDuet,  a  system  that  enables real-time counterpoint improvisation between a human anda machine.  This system uses a recurrent neural network toprocess the human musician’s monophonic performance ona MIDI keyboard and generates the machine’s monophonic performance in real time. We  develop a GUI to visualize the generated music content and to facilitate this interaction. We  conduct  user  studies  with  13  musically  trained users  and  show  the  feasibility  of  two-party  duet  counterpoint improvisation and the effectiveness of BachDuet for this purpose.  We also conduct listening tests with 48 participants and show that they cannot tell the difference between duets generated by human-machine improvisation using BachDuet and those generated by human-human improvisation.  Objective evaluation is also conducted to assess the degree to which these improvisations adhere to common rules of counterpoint, showing promising results.</p>

				<h2>Citation:</h2>

				



Christodoulos Benetatos, Joseph VanderStel, and Zhiyao Duan. 2020. 


BachDuet: A Deep Learning System for Human-Machine Counterpoint Improvisation. 


<em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 
DOI: <a href="https://doi.org/10.5281/zenodo.4813234">10.5281/zenodo.4813234</a>



				<h2>BibTeX Entry:</h2>

<pre>
@inproceedings{NIME20_125,
 abstract = {During theBaroque period, improvisation was a key element of music performance and education. Great musicians, such as J.S. Bach, were better known as improvisers than composers. Today,  however,  there  is  a  lack  of  improvisation culture in classical music performance and education; classical musicians either are not trained to improvise, or cannot find other people to improvise with.  Motivated by this observation,  we  develop BachDuet,  a  system  that  enables real-time counterpoint improvisation between a human anda machine.  This system uses a recurrent neural network toprocess the human musician’s monophonic performance ona MIDI keyboard and generates the machine’s monophonic performance in real time. We  develop a GUI to visualize the generated music content and to facilitate this interaction. We  conduct  user  studies  with  13  musically  trained users  and  show  the  feasibility  of  two-party  duet  counterpoint improvisation and the effectiveness of BachDuet for this purpose.  We also conduct listening tests with 48 participants and show that they cannot tell the difference between duets generated by human-machine improvisation using BachDuet and those generated by human-human improvisation.  Objective evaluation is also conducted to assess the degree to which these improvisations adhere to common rules of counterpoint, showing promising results.},
 address = {Birmingham, UK},
 author = {Benetatos, Christodoulos and VanderStel, Joseph and Duan, Zhiyao},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.4813234},
 editor = {Romain Michon and Franziska Schroeder},
 issn = {2220-4806},
 month = {July},
 pages = {635--640},
 presentation-video = {https://youtu.be/wFGW0QzuPPk},
 publisher = {Birmingham City University},
 title = {BachDuet: A Deep Learning System for Human-Machine Counterpoint Improvisation},
 url = {https://www.nime.org/proceedings/2020/nime2020_paper125.pdf},
 year = {2020}
}

</pre>
			</article>
		</main>
		<footer class="footer">
  <div class="container">
    <div class="copyright  typeset">
      <small class="small">© NIME 2024</small>
    </div>

    
<nav class="nav  nav--footer">
  <ul class="list list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/#top">Back to top</a>
      </li>
    
  </ul>
</nav>


  </div>
</footer>

	</body>
</html>
