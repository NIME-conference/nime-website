<!-- copied out of alembic's default template. -->
<!doctype html>
<html lang="en-GB">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="manifest" href="/nime/manifest.json">
    <meta name="theme-color" content="#242e2b"/>
		<link rel="stylesheet" href="/nime/assets/styles.css">
    
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@16px.png" sizes="16x16">
    <link rel="apple-touch-icon" sizes="16x16" href="/assets/logos/logo@16px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@32px.png" sizes="32x32">
    <link rel="apple-touch-icon" sizes="32x32" href="/assets/logos/logo@32px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@96px.png" sizes="96x96">
    <link rel="apple-touch-icon" sizes="96x96" href="/assets/logos/logo@96px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@120px.png" sizes="120x120">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/logos/logo@120px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@144px.png" sizes="144x144">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/logos/logo@144px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@180px.png" sizes="180x180">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/logos/logo@180px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@512px.png" sizes="512x512">
    <link rel="apple-touch-icon" sizes="512x512" href="/assets/logos/logo@512px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@1024px.png" sizes="1024x1024">
    <link rel="apple-touch-icon" sizes="1024x1024" href="/assets/logos/logo@1024px.png">
  

<link rel="shortcut icon" href="/assets/logos/nime.png">

		<!-- Overwrite this file with code you want before the closing head tag -->


		
  </head>

	<body>
		<header class="header">
  <div class="container">
    <a class="logo" href="/nime/">
  <img src="/nime/assets/logos/nime.png" alt="NIME logo">
</a>


    
<nav class="nav  nav--header">
  <ul class="list  list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/">Home</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/past-nimes/">Past NIMEs</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/archives/">Proceedings</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/music/">Music</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/hosting/">Hosting</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/committee/">Committee</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/list/">Mailing List</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/statements/">Statements</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="https://forum.nime.org/">Forum</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/mentorship/">Mentorship</a>
      </li>
    
  </ul>
  <button class="button  button--nav" aria-label="Menu toggle">
    <svg width="16" height="16" class="icon  icon--nav" role="img" alt="Menu"><title>Menu</title>
<use xlink:href="#nav" fill="CurrentColor"></use></svg>

  </button>
</nav>


<script type="text/javascript">
  // Get list and button
  const navList = document.querySelector('.header .list--nav')
  const button  = document.querySelector('.header .button--nav')

  // Hide nav and apply toggle
  const collapseNav = () => {
    if (document.body.clientWidth < 640) {
      navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
    } else {
      navList.removeAttribute('style')
    }

    button.onclick = () => {
      navList.style.setProperty('transition', `margin .1s`)
      if (navList.style.getPropertyValue('--listHeight')) {
        navList.style.removeProperty('--listHeight')
      } else {
        navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
      }
    }
  }

  collapseNav()

  // Check on resize if to collapse nav
  window.addEventListener('resize', () => {
    collapseNav()
  })
</script>

  </div>

  






</header>

		<main class="main container">
			<article class="article article--page content typeset">
				
				<h1>Comparative Latency Analysis of Optical and Inertial Motion Capture Systems for Gestural Analysis and Musical Performance</h1>
				
				<h4>



Geise Santos, Johnty Wang, Carolina Brum, Marcelo M. Wanderley, Tiago Tavares, and Anderson Rocha</h4>
				
				<p>Proceedings of the International Conference on New Interfaces for Musical Expression</p>
				
				<ul>
					<li>Year: 2021</li>
					<li>Location: Shanghai, China</li>
					
					
					<li>Article Number: 51</li>
					
					<li>DOI: <a href="https://doi.org/10.21428/92fbeb44.51b1c3a1">10.21428/92fbeb44.51b1c3a1 (Link to paper)</a>
</li>
					
					<li><a href="https://youtu.be/a1TVvr9F7hE">Presentation Video</a></li>
					
					
					
				</ul>
				
				<h2>Abstract:</h2>
				
				<p>Wireless sensor-based technologies are becoming increasingly accessible and widely explored in interactive musical performance due to their ubiquity and low-cost, which brings the necessity of understanding the capabilities and limitations of these sensors. This is usually approached by using a reference system, such as an optical motion capture system, to assess the signals’ properties. However, this process raises the issue of synchronizing the signal and the reference data streams, as each sensor is subject to different latency, time drift, reference clocks and initialization timings. This paper presents an empirical quantification of the latency communication stages in a setup consisting of a Qualisys optical motion capture (mocap) system and a wireless microcontroller-based sensor device. We performed event-to-end tests on the critical components of the hybrid setup to determine the synchronization suitability. Overall, further synchronization is viable because of the near individual average latencies of around 25ms for both the mocap system and the wireless sensor interface.</p>

				<h2>Citation:</h2>

				



Geise Santos, Johnty Wang, Carolina Brum, Marcelo M. Wanderley, Tiago Tavares, and Anderson Rocha. 2021. 


Comparative Latency Analysis of Optical and Inertial Motion Capture Systems for Gestural Analysis and Musical Performance. 


<em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 
DOI: <a href="https://doi.org/10.21428/92fbeb44.51b1c3a1">10.21428/92fbeb44.51b1c3a1</a>



				<h2>BibTeX Entry:</h2>

<pre>
@inproceedings{NIME21_51,
 abstract = {Wireless sensor-based technologies are becoming increasingly accessible and widely explored in interactive musical performance due to their ubiquity and low-cost, which brings the necessity of understanding the capabilities and limitations of these sensors. This is usually approached by using a reference system, such as an optical motion capture system, to assess the signals’ properties. However, this process raises the issue of synchronizing the signal and the reference data streams, as each sensor is subject to different latency, time drift, reference clocks and initialization timings. This paper presents an empirical quantification of the latency communication stages in a setup consisting of a Qualisys optical motion capture (mocap) system and a wireless microcontroller-based sensor device. We performed event-to-end tests on the critical components of the hybrid setup to determine the synchronization suitability. Overall, further synchronization is viable because of the near individual average latencies of around 25ms for both the mocap system and the wireless sensor interface.},
 address = {Shanghai, China},
 articleno = {51},
 author = {Santos, Geise and Wang, Johnty and Brum, Carolina and Wanderley, Marcelo M. and Tavares, Tiago and Rocha, Anderson},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.21428/92fbeb44.51b1c3a1},
 issn = {2220-4806},
 month = {June},
 presentation-video = {https://youtu.be/a1TVvr9F7hE},
 title = {Comparative Latency Analysis of Optical and Inertial Motion Capture Systems for Gestural Analysis and Musical Performance},
 url = {https://nime.pubpub.org/pub/wmcqkvw1},
 year = {2021}
}

</pre>
			</article>
		</main>
		<footer class="footer">
  <div class="container">
    <div class="copyright  typeset">
      <small class="small">© NIME 2024</small>
    </div>

    
<nav class="nav  nav--footer">
  <ul class="list list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/#top">Back to top</a>
      </li>
    
  </ul>
</nav>


  </div>
</footer>

	</body>
</html>
