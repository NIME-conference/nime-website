<!-- copied out of alembic's default template. -->
<!doctype html>
<html lang="en-GB">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
		<link rel="manifest" href="/nime/manifest.json">
    <meta name="theme-color" content="#242e2b"/>
		<link rel="stylesheet" href="/nime/assets/styles.css">
    
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@16px.png" sizes="16x16">
    <link rel="apple-touch-icon" sizes="16x16" href="/assets/logos/logo@16px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@32px.png" sizes="32x32">
    <link rel="apple-touch-icon" sizes="32x32" href="/assets/logos/logo@32px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@96px.png" sizes="96x96">
    <link rel="apple-touch-icon" sizes="96x96" href="/assets/logos/logo@96px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@120px.png" sizes="120x120">
    <link rel="apple-touch-icon" sizes="120x120" href="/assets/logos/logo@120px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@144px.png" sizes="144x144">
    <link rel="apple-touch-icon" sizes="144x144" href="/assets/logos/logo@144px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@180px.png" sizes="180x180">
    <link rel="apple-touch-icon" sizes="180x180" href="/assets/logos/logo@180px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@512px.png" sizes="512x512">
    <link rel="apple-touch-icon" sizes="512x512" href="/assets/logos/logo@512px.png">
  
    <link rel="icon" type="image/png" href="/assets/logos/logo@1024px.png" sizes="1024x1024">
    <link rel="apple-touch-icon" sizes="1024x1024" href="/assets/logos/logo@1024px.png">
  

<link rel="shortcut icon" href="/assets/logos/nime.png">

		<!-- Overwrite this file with code you want before the closing head tag -->


		
  </head>

	<body>
		<header class="header">
  <div class="container">
    <a class="logo" href="/nime/">
  <img src="/nime/assets/logos/nime.png" alt="NIME logo">
</a>


    
<nav class="nav  nav--header">
  <ul class="list  list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/">Home</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/past-nimes/">Past NIMEs</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/archives/">Proceedings</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/music/">Music</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/hosting/">Hosting</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/committee/">Committee</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/list/">Mailing List</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/statements/">Statements</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="https://forum.nime.org/">Forum</a>
      </li>
    

      

      <li class="item  item--nav">
        <a href="/nime/mentorship/">Mentorship</a>
      </li>
    
  </ul>
  <button class="button  button--nav" aria-label="Menu toggle">
    <svg width="16" height="16" class="icon  icon--nav" role="img" alt="Menu"><title>Menu</title>
<use xlink:href="#nav" fill="CurrentColor"></use></svg>

  </button>
</nav>


<script type="text/javascript">
  // Get list and button
  const navList = document.querySelector('.header .list--nav')
  const button  = document.querySelector('.header .button--nav')

  // Hide nav and apply toggle
  const collapseNav = () => {
    if (document.body.clientWidth < 640) {
      navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
    } else {
      navList.removeAttribute('style')
    }

    button.onclick = () => {
      navList.style.setProperty('transition', `margin .1s`)
      if (navList.style.getPropertyValue('--listHeight')) {
        navList.style.removeProperty('--listHeight')
      } else {
        navList.style.setProperty('--listHeight', `-${navList.offsetHeight}px`)
      }
    }
  }

  collapseNav()

  // Check on resize if to collapse nav
  window.addEventListener('resize', () => {
    collapseNav()
  })
</script>

  </div>

  






</header>

		<main class="main container">
			<article class="article article--page content typeset">
				
				<h1>Designing Gestures for Continuous Sonic Interaction</h1>
				
				<h4>



Atau Tanaka, Balandino Di Donato, Michael Zbyszynski, and Geert Roks</h4>
				
				<p>Proceedings of the International Conference on New Interfaces for Musical Expression</p>
				
				<ul>
					<li>Year: 2019</li>
					<li>Location: Porto Alegre, Brazil</li>
					
					<li>Pages: 180–185</li>
					
					
					<li>DOI: <a href="https://doi.org/10.5281/zenodo.3672916">10.5281/zenodo.3672916</a>
</li>
					<li><a href="http://www.nime.org/proceedings/2019/nime2019_paper036.pdf">PDF link</a></li>
					
					
					
					
				</ul>
				
				<h2>Abstract:</h2>
				
				<p>This paper presents a system that allows users to quickly try different ways to train neural networks and temporal modeling techniques to associate arm gestures with time varying sound. We created a software framework for this, and designed three interactive sounds and presented them to participants in a workshop based study. We build upon previous work in sound-tracing and mapping-by-demonstration to ask the participants to design gestures with which to perform the given sounds using a multimodal, inertial measurement (IMU) and muscle sensing (EMG) device. We presented the user with four techniques for associating sensor input to synthesizer parameter output. Two were classical techniques from the literature, and two proposed different ways to capture dynamic gesture in a neural network. These four techniques were: 1.) A Static Position regression training procedure, 2.) A Hidden Markov based temporal modeler, 3.) Whole Gesture capture to a neural network, and 4.) a Windowed method using the position-based procedure on the fly during the performance of a dynamic gesture. Our results show trade-offs between accurate, predictable reproduction of the source sounds and exploration of the gesture-sound space. Several of the users were attracted to our new windowed method for capturing gesture anchor points on the fly as training data for neural network based regression. This paper will be of interest to musicians interested in going from sound design to gesture design and offers a workflow for quickly trying different mapping-by-demonstration techniques.</p>

				<h2>Citation:</h2>

				



Atau Tanaka, Balandino Di Donato, Michael Zbyszynski, and Geert Roks. 2019. 


Designing Gestures for Continuous Sonic Interaction. 


<em>Proceedings of the International Conference on New Interfaces for Musical Expression</em>. 
DOI: <a href="https://doi.org/10.5281/zenodo.3672916">10.5281/zenodo.3672916</a>



				<h2>BibTeX Entry:</h2>

<pre>
@inproceedings{Tanaka2019,
 abstract = {This paper presents a system that allows users to quickly try different ways to train neural networks and temporal modeling techniques to associate arm gestures with time varying sound. We created a software framework for this, and designed three interactive sounds and presented them to participants in a workshop based study. We build upon previous work in sound-tracing and mapping-by-demonstration to ask the participants to design gestures with which to perform the given sounds using a multimodal, inertial measurement (IMU) and muscle sensing (EMG) device. We presented the user with four techniques for associating sensor input to synthesizer parameter output. Two were classical techniques from the literature, and two proposed different ways to capture dynamic gesture in a neural network. These four techniques were: 1.) A Static Position regression training procedure, 2.) A Hidden Markov based temporal modeler, 3.) Whole Gesture capture to a neural network, and 4.) a Windowed method using the position-based procedure on the fly during the performance of a dynamic gesture. Our results show trade-offs between accurate, predictable reproduction of the source sounds and exploration of the gesture-sound space. Several of the users were attracted to our new windowed method for capturing gesture anchor points on the fly as training data for neural network based regression. This paper will be of interest to musicians interested in going from sound design to gesture design and offers a workflow for quickly trying different mapping-by-demonstration techniques.},
 address = {Porto Alegre, Brazil},
 author = {Atau Tanaka and Di Donato, Balandino and Michael Zbyszynski and Geert Roks},
 booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
 doi = {10.5281/zenodo.3672916},
 editor = {Marcelo Queiroz and Anna Xambó Sedó},
 issn = {2220-4806},
 month = {June},
 pages = {180--185},
 publisher = {UFRGS},
 title = {Designing Gestures for Continuous Sonic Interaction},
 url = {http://www.nime.org/proceedings/2019/nime2019_paper036.pdf},
 year = {2019}
}

</pre>
			</article>
		</main>
		<footer class="footer">
  <div class="container">
    <div class="copyright  typeset">
      <small class="small">© NIME 2023</small>
    </div>

    
<nav class="nav  nav--footer">
  <ul class="list list--nav">
    

      

      <li class="item  item--nav">
        <a href="/nime/#top">Back to top</a>
      </li>
    
  </ul>
</nav>


  </div>
</footer>

	</body>
</html>
